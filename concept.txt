=== technologies ===
== backend/server ==
- postgresql (database)
- typeORM (typescript ORM) https://typeorm.io/
- apollo (graphql server) https://www.apollographql.com/docs/apollo-server/
- graphql (query langague)
- node.js [express] (server side development)
- typegraphql (framework for graphql api in node.js) https://typegraphql.com/
- redis (in memory datastore)
- nodemailer (handles email sending)

== frontend ==
- react
- typescript
- urql (graphql client) https://formidable.com/open-source/urql/
- next.js with chakra [urql has next.js integration for SSR]
- codegen (graphql code generator) https://www.graphql-code-generator.com/

=== concept ===
== backend/server ==
1) TypeORM vs MikroORM
- ORM is a technique that lets you query and manipulate data from a database using an object-oriented paradigm.
- there are db relationships such as many-many/many-one/one-many decorators
- typeorm style slightly cleaner than mikroorm
- @Column decorator means adding a column into the database table
- @Field decorator means exposing to graphql

2) Sessions and Cookies in Redis
- allows user to stay logged in and continue to do actions on the website
--> req.session.userId = user.id; (storing data into session)
--> {userId: 1} send to redis and stored in redis (redis is a key-value store. {sess:qwefsdfgdsd : {userId: 1}})
--> express-session will set a cookie on my browser asdfasdf123dsdf
--> cookie value is a signed version of redis key
--> when user makes a request, cookie value sent to server
--> cookie value will be decrypted by our secret set. (turns asdfasdf123dsdf into sess:qwefsdfgdsd)
--> makes a request to redis with decrypted key to retrieve the data
--> retrieves req.session = {userID: 1}

3) Apollo server (graphql server with Node.js)
- a library that helps you connect a graphql schema to a HTTP server in node
- expose APIs for client to call on graphql
- http://localhost:4000/graphql

4) Typegraphql
--> typegraphql has a middleware function that runs before the resolvers
--> middleware function can be used for global error handling

== frontend ==
1) Urql (graphql client)
- caching in urql is not normalized
- graphcache allows for normalized caching https://formidable.com/open-source/urql/docs/graphcache/
--> can wrap each independent page and decide ssr
--> urql can handle global error as well using errorExchange

2) Codegen (graphql code generator)
- generate typescript typesafe for our queries and urql hooks from graphql code
--> generated graphql.tsx file contains graphql hooks for use
--> mutation hooks: [, 2nd_param*]
--> query hooks: [{data,fetching}]

3) Server Side Rendering (SSR)
me --> browse http://localhost:3000
--> requests to next.js server
--> requests to graphql server http://localhost:4000
--> building the HTML
--> sending back to browser

ssr vs client side
ssr: browser -> next.js -> graphql api
client: browser -> graphql api

when page first loads, does a ssr request, so cookie not sent to graphql api
--> we need to then forward the cookie from our next.js to our graphql api


=== development tips ===
1) tsc -w creates a dist folder (convert ts code to js code)
--> compiling js code is much faster than ts code
2) nodemon listens to live changes and auto recompiles
3) graphql-codegen --config codegen.yml (generates graphql.tsx from graphql code)
4) create a me query to check whether a user is logged in, and a custom hook to check if authenticated
5) mockaroo to create mock data
6) pagination can be done from limit and cursor




DataLoader
--> Initially, when querying for table with a need to join, (creatorId -post+user- and voteStatus -post+user-),
you can write a big query to handle everything.
- bad thing about this is sometimes you query for the information that you do not need, eg creatorId

--> can use a field resolver to handle above disadvantage, where you will only make the query when you ask for it
- however, normal field resolver query will result in the N+1 problem, where querying can be slow and heavy (querying 1 time for 1 post, 100 times for 100 posts)

--> hence, can use dataloader to solve the N+1 problem, where dataloader will basically batch the entire queries into 1 queries
--> now you can have 1 query to acquire information whenever you need it


